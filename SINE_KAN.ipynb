{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61acee2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 145\u001b[0m\n\u001b[0;32m    141\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[43mtrain_sine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 96\u001b[0m, in \u001b[0;36mtrain_sine\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Model: 1 input → hidden_width B-spline modules → 1 output\u001b[39;00m\n\u001b[0;32m     94\u001b[0m model \u001b[38;5;241m=\u001b[39m KAN(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, hidden_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     95\u001b[0m             output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\optim\\adam.py:101\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor betas[1] must be 1-element\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     89\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     90\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\optim\\optimizer.py:400\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    397\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\_compile.py:46\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive, wrapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:58\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     59\u001b[0m     config,\n\u001b[0;32m     60\u001b[0m     exc,\n\u001b[0;32m     61\u001b[0m     graph_break_hints,\n\u001b[0;32m     62\u001b[0m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[0;32m     63\u001b[0m     trace_rules,\n\u001b[0;32m     64\u001b[0m     variables,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m     get_indexof,\n\u001b[0;32m     68\u001b[0m     JUMP_OPNAMES,\n\u001b[0;32m     69\u001b[0m     livevars_analysis,\n\u001b[0;32m     70\u001b[0m     propagate_line_nums,\n\u001b[0;32m     71\u001b[0m )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m     cleaned_instructions,\n\u001b[0;32m     74\u001b[0m     create_call_function,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     unique_id,\n\u001b[0;32m     82\u001b[0m )\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:47\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, cast, Optional, Union\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_operators\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_content_store\u001b[39;00m\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\_inductor\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, IO, Literal, Optional, TYPE_CHECKING, Union\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandalone_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompiledArtifact  \u001b[38;5;66;03m# noqa: TC001\u001b[39;00m\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\_inductor\\config.py:533\u001b[0m\n\u001b[0;32m    528\u001b[0m autoheuristic_log_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_AUTOHEURISTIC_LOG_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEFAULT\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Disabled by default on ROCm, opt-in if model utilises NHWC convolutions\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m layout_opt_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mhip \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m layout_optimization \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    535\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_LAYOUT_OPTIMIZATION\u001b[39m\u001b[38;5;124m\"\u001b[39m, layout_opt_default) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m )\n\u001b[0;32m    538\u001b[0m force_layout_optimization \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_FORCE_LAYOUT_OPT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mi:\\Desktop\\KAN\\env\\lib\\site-packages\\torch\\__init__.py:2745\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   2742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[0;32m   2743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 2745\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "# File: ./kan_sine.py\n",
    "# Purpose: Train KAN-inspired model on y=sin(x) regression task\n",
    "#          and visualize learned spline activations.\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# B-spline activation function\n",
    "# -----------------------------\n",
    "class BSplineActivation(nn.Module):\n",
    "    def __init__(self, input_dim, num_knots=15, degree=3, knot_min=-np.pi, knot_max=np.pi):\n",
    "        \"\"\"\n",
    "        Per-feature B-spline activation with learned weights.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.degree = degree\n",
    "\n",
    "        knots = np.linspace(knot_min, knot_max, num_knots).astype(np.float32)\n",
    "        self.register_buffer(\"knots\", torch.tensor(knots))\n",
    "\n",
    "        self.num_basis = num_knots - degree - 1\n",
    "        # one weight vector per feature\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.randn(input_dim, self.num_basis) * 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, D = x.shape\n",
    "        out = torch.empty_like(x)\n",
    "        for i in range(D):\n",
    "            B = self._b_spline_matrix(x[:, i])\n",
    "            out[:, i] = B @ self.weights[i]\n",
    "        return out\n",
    "\n",
    "    def _N(self, j, k, x, knots):\n",
    "        \"\"\"Cox–de Boor recursion.\"\"\"\n",
    "        if k == 0:\n",
    "            return ((x >= knots[j]) & (x < knots[j + 1])).float()\n",
    "        denom1 = knots[j + k] - knots[j]\n",
    "        denom2 = knots[j + k + 1] - knots[j + 1]\n",
    "        term1, term2 = 0, 0\n",
    "        if denom1.item() != 0:\n",
    "            term1 = ((x - knots[j]) / denom1) * self._N(j, k - 1, x, knots)\n",
    "        if denom2.item() != 0:\n",
    "            term2 = ((knots[j + k + 1] - x) / denom2) * \\\n",
    "                self._N(j + 1, k - 1, x, knots)\n",
    "        return term1 + term2\n",
    "\n",
    "    def _b_spline_matrix(self, x):\n",
    "        n_intervals = self.knots.numel() - 1\n",
    "        B = torch.zeros((x.shape[0], self.num_basis), device=x.device)\n",
    "        for j in range(n_intervals - self.degree):\n",
    "            B[:, j] = self._N(j, self.degree, x, self.knots)\n",
    "        return B\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# KAN-inspired model\n",
    "# -----------------------------\n",
    "class KAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_width, output_dim, num_knots=15, degree=3):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            BSplineActivation(input_dim, num_knots, degree, -np.pi, np.pi)\n",
    "            for _ in range(hidden_width)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_width * input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([layer(x) for layer in self.hidden_layers], dim=1)\n",
    "        return self.output_layer(h)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training on sine function\n",
    "# -----------------------------\n",
    "def train_sine():\n",
    "    # Generate mock dataset\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    X = np.linspace(-np.pi, np.pi, 200).astype(np.float32)\n",
    "    y = np.sin(X) + 0.05 * np.random.randn(*X.shape).astype(np.float32)\n",
    "\n",
    "    X = torch.tensor(X).unsqueeze(1)  # (200,1)\n",
    "    y = torch.tensor(y).unsqueeze(1)  # (200,1)\n",
    "\n",
    "    # Model: 1 input → hidden_width B-spline modules → 1 output\n",
    "    model = KAN(input_dim=1, hidden_width=5,\n",
    "                output_dim=1, num_knots=15, degree=3)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(2000):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 400 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss={loss.item():.4f}\")\n",
    "\n",
    "    # Predictions for visualization\n",
    "    with torch.no_grad():\n",
    "        y_fit = model(X)\n",
    "\n",
    "    # Plot sine vs learned curve\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(X.numpy(), y.numpy(), label=\"True (noisy)\", s=10, alpha=0.6)\n",
    "    plt.plot(X.numpy(), np.sin(X.numpy()),\n",
    "             label=\"True sin(x)\", color=\"green\", linewidth=2)\n",
    "    plt.plot(X.numpy(), y_fit.numpy(),\n",
    "             label=\"Model prediction\", color=\"red\", linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.title(\"KAN approximation of sin(x)\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot learned activation functions from all hidden layers\n",
    "    x_grid = torch.linspace(-np.pi, np.pi, 300).unsqueeze(1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for idx, layer in enumerate(model.hidden_layers):\n",
    "        B = layer._b_spline_matrix(x_grid.squeeze(1))\n",
    "        w = layer.weights[0]   # weights for the only input feature\n",
    "        activation = B @ w\n",
    "        plt.plot(x_grid.numpy(), activation.detach().numpy(),\n",
    "                 label=f\"Layer {idx}\")\n",
    "    plt.title(\"Learned spline activations per hidden layer\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"activation\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_sine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39a7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
